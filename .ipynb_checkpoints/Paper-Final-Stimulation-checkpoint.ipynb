{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5be0b2c-2d66-4d65-9c63-b715c0a63847",
   "metadata": {},
   "source": [
    "## Software requirements classification using Machine Learning and NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5c41f6-db29-4b93-b79e-452d2d17bddb",
   "metadata": {},
   "source": [
    "The objective of this project is to offer insights into the comparative performance of classifiers by employing common machine learning algorithms and feature extraction techniques within the domain of natural language processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7303eca9-9733-4fb1-9493-e346cebcea39",
   "metadata": {},
   "source": [
    "## Phase 1: NLP Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0d053473-3806-43b8-823c-05feff856261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing warnings\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30914a46-aa70-478b-80e6-946094c2d593",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Requirement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PE</td>\n",
       "      <td>The system shall refresh the display every 60 seconds.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LF</td>\n",
       "      <td>The application shall match the color of the schema set forth by Department of Homeland Security</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>If projected  the data must be readable.  On a 10x10 projection screen  90% of viewers must be able to read Event / Activity data from a viewing distance of 30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A</td>\n",
       "      <td>The product shall be available during normal business hours. As long as the user has access to the client PC  the system will be available 99% of the time during the first six months of operation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>If projected  the data must be understandable. On a 10x10 projection screen  90% of viewers must be able to determine that Events or Activities are occuring in current time from a viewing distance of 100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SE</td>\n",
       "      <td>The product shall ensure that it can only be accessed by authorized users.  The product will be able to distinguish between authorized and unauthorized users in all access attempts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>US</td>\n",
       "      <td>The product shall be intuitive and self-explanatory.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PE</td>\n",
       "      <td>The product shall respond fast to keep up-to-date data in the display.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>F</td>\n",
       "      <td>The system shall have a MDI form that allows for the viewing of the graph and the data table.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>F</td>\n",
       "      <td>The system shall display Events in a vertical table by time.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Type  \\\n",
       "0   PE   \n",
       "1   LF   \n",
       "2   US   \n",
       "3    A   \n",
       "4   US   \n",
       "5   SE   \n",
       "6   US   \n",
       "7   PE   \n",
       "8    F   \n",
       "9    F   \n",
       "\n",
       "                                                                                                                                                                                                    Requirement  \n",
       "0                                                                                                                                                        The system shall refresh the display every 60 seconds.  \n",
       "1                                                                                                              The application shall match the color of the schema set forth by Department of Homeland Security  \n",
       "2                                               If projected  the data must be readable.  On a 10x10 projection screen  90% of viewers must be able to read Event / Activity data from a viewing distance of 30  \n",
       "3          The product shall be available during normal business hours. As long as the user has access to the client PC  the system will be available 99% of the time during the first six months of operation.  \n",
       "4   If projected  the data must be understandable. On a 10x10 projection screen  90% of viewers must be able to determine that Events or Activities are occuring in current time from a viewing distance of 100  \n",
       "5                          The product shall ensure that it can only be accessed by authorized users.  The product will be able to distinguish between authorized and unauthorized users in all access attempts  \n",
       "6                                                                                                                                                        The product shall be intuitive and self-explanatory.    \n",
       "7                                                                                                                                        The product shall respond fast to keep up-to-date data in the display.  \n",
       "8                                                                                                                 The system shall have a MDI form that allows for the viewing of the graph and the data table.  \n",
       "9                                                                                                                                                  The system shall display Events in a vertical table by time.  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing pandas and loading dataset\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "\n",
    "dataset = pd.read_csv('software_requirements_extended.csv')\n",
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99f800a6-f259-41d5-90d6-77d5208144df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 977 entries, 0 to 976\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   Type         977 non-null    object\n",
      " 1   Requirement  977 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 15.4+ KB\n"
     ]
    }
   ],
   "source": [
    "# checking info of the dataset\n",
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "392cb904-8e2d-49c6-a905-ce9760c84401",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Requirement</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>977</td>\n",
       "      <td>977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>14</td>\n",
       "      <td>976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>FR</td>\n",
       "      <td>Only registered customers can purchase streaming movies.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>312</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Type                                               Requirement\n",
       "count   977                                                       977\n",
       "unique   14                                                       976\n",
       "top      FR  Only registered customers can purchase streaming movies.\n",
       "freq    312                                                         2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking description of the dataset\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dcaee5b-3aac-471d-8619-115ac5558307",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Converting the read dataset in to a list of tuples, each tuple(row) contianing the message and it's label\n",
    "data_set = []\n",
    "for index,row in dataset.iterrows():\n",
    "    data_set.append((row['Type'], row['Requirement']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0129656f-43ac-4a75-97eb-8a3c49c69ac2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m merged_text \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     16\u001b[0m [merged_text\u001b[38;5;241m.\u001b[39mextend(sublist) \u001b[38;5;28;01mfor\u001b[39;00m sublist \u001b[38;5;129;01min\u001b[39;00m words]\n\u001b[0;32m---> 17\u001b[0m \u001b[43mplot_word_frequency\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmerged_text\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 9\u001b[0m, in \u001b[0;36mplot_word_frequency\u001b[0;34m(words, top_n)\u001b[0m\n\u001b[1;32m      7\u001b[0m labels \u001b[38;5;241m=\u001b[39m [element[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m word_freq\u001b[38;5;241m.\u001b[39mmost_common(top_n)]\n\u001b[1;32m      8\u001b[0m counts \u001b[38;5;241m=\u001b[39m [element[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m element \u001b[38;5;129;01min\u001b[39;00m word_freq\u001b[38;5;241m.\u001b[39mmost_common(top_n)]\n\u001b[0;32m----> 9\u001b[0m plot \u001b[38;5;241m=\u001b[39m \u001b[43msns\u001b[49m\u001b[38;5;241m.\u001b[39mbarplot(x\u001b[38;5;241m=\u001b[39mlabels, y\u001b[38;5;241m=\u001b[39mcounts)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m plot\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk import FreqDist\n",
    "import seaborn as sns\n",
    "\n",
    "# plotting freq distribution to check the stopwords\n",
    "def plot_word_frequency(words, top_n=10):\n",
    "    word_freq = FreqDist(words)\n",
    "    labels = [element[0] for element in word_freq.most_common(top_n)]\n",
    "    counts = [element[1] for element in word_freq.most_common(top_n)]\n",
    "    plot = sns.barplot(x=labels, y=counts)\n",
    "    return plot\n",
    "\n",
    "\n",
    "words = [word_tokenize(text) for label, text in data_set]\n",
    "\n",
    "merged_text = []\n",
    "[merged_text.extend(sublist) for sublist in words]\n",
    "plot_word_frequency(merged_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc082ad-2e55-4d1f-9b05-18716801263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP preprocessing steps combined\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "import numpy as np\n",
    "from nltk import FreqDist\n",
    "import seaborn as sns\n",
    "\n",
    "# Download necessary resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text)\n",
    "        \n",
    "    # Lowercasing\n",
    "    tokens = [word.lower() for word in tokens]\n",
    "    \n",
    "    # Removing punctuation\n",
    "    tokens = [word for word in tokens if word not in string.punctuation]\n",
    "    \n",
    "    # Removing stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in tokens]\n",
    "    \n",
    "    # Join tokens back into text\n",
    "    preprocessed_text = ' '.join(tokens)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "# Preprocess the dataset\n",
    "preprocessed_dataset = [(label, preprocess_text(text)) for label, text in data_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fe2249-6283-4929-ad49-4ea999f64b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries for model building and word vectorization\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "# Separate labels and preprocessed texts\n",
    "labels, texts = zip(*preprocessed_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094fe175-5ff1-44d1-997e-646e5a380c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(texts, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabd17b6-a9c8-4ce8-844c-5bbe6503c66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF Vectorization\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8f9721-ef5f-475d-af24-959d7707828a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec Vectorization\n",
    "word2vec_model = Word2Vec(sentences=[text.split() for text in texts], min_count=1)\n",
    "word2vec_words = set(word2vec_model.wv.index_to_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567411bc-1640-43e7-8d36-86e491637f89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_averaging(model, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in model.wv:\n",
    "            mean.append(model.wv[word])\n",
    "            all_words.add(model.wv.key_to_index[word])\n",
    "    \n",
    "    if not mean:\n",
    "        return np.zeros(model.vector_size,)\n",
    "    \n",
    "    mean = np.array(mean).mean(axis=0)\n",
    "    return mean\n",
    "\n",
    "def word_vectorizer(model, documents):\n",
    "    return np.vstack([word_averaging(model, doc.split()) for doc in documents])\n",
    "\n",
    "X_train_word2vec = word_vectorizer(word2vec_model, X_train)\n",
    "X_test_word2vec = word_vectorizer(word2vec_model, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ea1de9-102b-4cd8-809b-8587f4398712",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Building and Evaluation\n",
    "# You can replace these placeholders with your preferred ML algorithms\n",
    "# For simplicity, let's use Logistic Regression and Random Forest for demonstration\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Define models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Random Forest\": RandomForestClassifier()\n",
    "}\n",
    "\n",
    "# Define empty dictionaries to store results\n",
    "results_tfidf = {}\n",
    "results_word2vec = {}\n",
    "\n",
    "# Train and evaluate models for TF-IDF\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_tfidf, y_train)\n",
    "    y_pred = model.predict(X_test_tfidf)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    print(accuracy)\n",
    "    results_tfidf[name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1}\n",
    "\n",
    "print(results_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d99022-8332-4844-93a2-7e491838ff18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate models for Word2Vec\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train_word2vec, y_train)\n",
    "    y_pred = model.predict(X_test_word2vec)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    results_word2vec[name] = {'Accuracy': accuracy, 'Precision': precision, 'Recall': recall, 'F1 Score': f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c58ebe-3ba6-4297-b636-c6e7a92ce98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print(\"Results for TF-IDF:\")\n",
    "for model, scores in results_tfidf.items():\n",
    "    print(f\"{model}: {scores}\")\n",
    "\n",
    "print(\"\\nResults for Word2Vec:\")\n",
    "for model, scores in results_word2vec.items():\n",
    "    print(f\"{model}: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d623b8a-5424-43c0-a1e0-79aeab8b907b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc4f625-c8b5-491f-9c48-8a0c2f4668db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df8f9e6c-1971-4f40-904a-9b10195d3371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e12d664-46ec-4af9-b318-d9d7a5040d66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
