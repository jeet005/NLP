{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5144b933-8b1b-4729-bb98-2de9868236e3",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39b7a9ac-9125-401c-9297-6ee05dde123d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### import necessary libraries\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "163e0041-2fb1-4b6c-bda0-128959bfc035",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Very orderly and methodical he looked, with a hand on each knee, and a loud watch ticking a sonorous sermon under his flapped newly bought waist-coat, as though it pitted its gravity and longevity against the levity and evanescence of the brisk fire.\n"
     ]
    }
   ],
   "source": [
    "text = \"Very orderly and methodical he looked, with a hand on each knee, and a loud watch ticking a sonorous sermon under his flapped newly bought waist-coat, as though it pitted its gravity and longevity against the levity and evanescence of the brisk fire.\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c9be075f-999a-4f8d-a439-b207d79c2947",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Very', 'orderly', 'and', 'methodical', 'he', 'looked', ',', 'with', 'a', 'hand', 'on', 'each', 'knee', ',', 'and', 'a', 'loud', 'watch', 'ticking', 'a', 'sonorous', 'sermon', 'under', 'his', 'flapped', 'newly', 'bought', 'waist-coat', ',', 'as', 'though', 'it', 'pitted', 'its', 'gravity', 'and', 'longevity', 'against', 'the', 'levity', 'and', 'evanescence', 'of', 'the', 'brisk', 'fire', '.']\n"
     ]
    }
   ],
   "source": [
    "# tokenise text\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29dbdb1b-76fc-456b-b0a6-1c12980ffc9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/sarab/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1dd43076-26ed-4bd9-8a55-2c653409e552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Very', 'orderly', 'and', 'methodical', 'he', 'looked', ',', 'with', 'a', 'hand', 'on', 'each', 'knee', ',', 'and', 'a', 'loud', 'watch', 'ticking', 'a', 'sonorous', 'sermon', 'under', 'his', 'flapped', 'newly', 'bought', 'waist-coat', ',', 'a', 'though', 'it', 'pitted', 'it', 'gravity', 'and', 'longevity', 'against', 'the', 'levity', 'and', 'evanescence', 'of', 'the', 'brisk', 'fire', '.']\n"
     ]
    }
   ],
   "source": [
    "wordnetlemmatizer = WordNetLemmatizer()\n",
    "lemmatized_words = [wordnetlemmatizer.lemmatize(token) for token in tokens]\n",
    "print(lemmatized_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70337b60-6969-4c1e-83f3-8ba0e218bf5a",
   "metadata": {},
   "source": [
    "#### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "79975f1c-46d2-4fd2-9c06-49f8b537cf14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['veri', 'orderli', 'and', 'method', 'he', 'look', ',', 'with', 'a', 'hand', 'on', 'each', 'knee', ',', 'and', 'a', 'loud', 'watch', 'tick', 'a', 'sonor', 'sermon', 'under', 'hi', 'flap', 'newli', 'bought', 'waist-coat', ',', 'as', 'though', 'it', 'pit', 'it', 'graviti', 'and', 'longev', 'against', 'the', 'leviti', 'and', 'evanesc', 'of', 'the', 'brisk', 'fire', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "stemmed = [stemmer.stem(token) for token in tokens]\n",
    "print(stemmed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4d8874c-9b7d-411e-ae80-ea21ac8e1f3a",
   "metadata": {},
   "source": [
    "#### Comparing Stemming and lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19455477-543c-42d2-81a1-2c28c5148eb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>token</th>\n",
       "      <th>stemmed</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Very</td>\n",
       "      <td>veri</td>\n",
       "      <td>Very</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>orderly</td>\n",
       "      <td>orderli</td>\n",
       "      <td>orderly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>methodical</td>\n",
       "      <td>method</td>\n",
       "      <td>methodical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>looked</td>\n",
       "      <td>look</td>\n",
       "      <td>looked</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>ticking</td>\n",
       "      <td>tick</td>\n",
       "      <td>ticking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>sonorous</td>\n",
       "      <td>sonor</td>\n",
       "      <td>sonorous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>his</td>\n",
       "      <td>hi</td>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>flapped</td>\n",
       "      <td>flap</td>\n",
       "      <td>flapped</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>newly</td>\n",
       "      <td>newli</td>\n",
       "      <td>newly</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>as</td>\n",
       "      <td>as</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>pitted</td>\n",
       "      <td>pit</td>\n",
       "      <td>pitted</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>its</td>\n",
       "      <td>it</td>\n",
       "      <td>it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>gravity</td>\n",
       "      <td>graviti</td>\n",
       "      <td>gravity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>longevity</td>\n",
       "      <td>longev</td>\n",
       "      <td>longevity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>levity</td>\n",
       "      <td>leviti</td>\n",
       "      <td>levity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>evanescence</td>\n",
       "      <td>evanesc</td>\n",
       "      <td>evanescence</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          token  stemmed   lemmatized\n",
       "0          Very     veri         Very\n",
       "1       orderly  orderli      orderly\n",
       "3    methodical   method   methodical\n",
       "5        looked     look       looked\n",
       "18      ticking     tick      ticking\n",
       "20     sonorous    sonor     sonorous\n",
       "23          his       hi          his\n",
       "24      flapped     flap      flapped\n",
       "25        newly    newli        newly\n",
       "29           as       as            a\n",
       "32       pitted      pit       pitted\n",
       "33          its       it           it\n",
       "34      gravity  graviti      gravity\n",
       "36    longevity   longev    longevity\n",
       "39       levity   leviti       levity\n",
       "41  evanescence  evanesc  evanescence"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(data={'token': tokens, 'stemmed': stemmed, 'lemmatized': lemmatized})\n",
    "df = df[['token', 'stemmed', 'lemmatized']]\n",
    "df[(df.token != df.stemmed) | (df.token != df.lemmatized)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0912655-428f-4cac-a6af-c47ea37e08d8",
   "metadata": {},
   "source": [
    "## Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50944229-88f3-4b84-9e2e-da4be6264f48",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'WordNetLemmatizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#### Why the lemmatization didn't worked properly ? \u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m wordnet_lemmatizer \u001b[38;5;241m=\u001b[39m \u001b[43mWordNetLemmatizer\u001b[49m()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(wordnet_lemmatizer\u001b[38;5;241m.\u001b[39mlemmatize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving\u001b[39m\u001b[38;5;124m\"\u001b[39m, pos\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(wordnet_lemmatizer\u001b[38;5;241m.\u001b[39mlemmatize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaving\u001b[39m\u001b[38;5;124m\"\u001b[39m, pos\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mv\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'WordNetLemmatizer' is not defined"
     ]
    }
   ],
   "source": [
    "#### Why the lemmatization didn't worked properly ? \n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "print(wordnet_lemmatizer.lemmatize(\"having\", pos='n'))\n",
    "print(wordnet_lemmatizer.lemmatize(\"having\", pos='v'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1dab9ea-5a4c-4f9e-8ec8-78160657a096",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
