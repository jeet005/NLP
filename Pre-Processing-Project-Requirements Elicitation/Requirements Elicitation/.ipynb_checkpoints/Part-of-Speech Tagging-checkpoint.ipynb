{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e5b6f69-ec2b-425e-9f13-4d9a1a44c7f1",
   "metadata": {},
   "source": [
    "## Part-of-Speech Tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02ebc21f-f43e-431d-892b-6d9bff87c687",
   "metadata": {},
   "source": [
    "We will look at the following four main techniques used for POS tagging:\n",
    "\n",
    "Lexicon-based\n",
    "\n",
    "Rule-based\n",
    "\n",
    "Probabilistic (or stochastic) techniques\n",
    "\n",
    "Deep learning techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c57f0b0-0067-4d83-9ba6-1bb9b6565fde",
   "metadata": {},
   "source": [
    "<b>Lexicon tagger</b> will tag 'run' basis the highest frequency tag. In most contexts, 'run' is likely to appear as a verb, implying that 'run' will be wrongly tagged in the first sentence.\n",
    "\n",
    " \n",
    "\n",
    "But if thereâ€™s a rule that is applied to the entire text, such as, 'replace VB with NN if the previous tag is DT', or 'tag all words ending with ing as VBG', the tag can be corrected. <b>Rule-based tagging</b> methods use such an approach.\n",
    "\n",
    " \n",
    "\n",
    "<b>Probabilistic taggers</b> don't naively assign the highest frequency tag to each word, instead, they look at slightly longer parts of the sequence and often use the tag(s) and the word(s) appearing before the target word to be tagged."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8c9ca87-2079-4555-8454-b09379f31347",
   "metadata": {},
   "source": [
    "## POS Tagging - Lexicon and Rule Based Taggers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79194f1a-f648-44d3-9c3f-0108882bca9a",
   "metadata": {},
   "source": [
    "### 1. Reading and understanding the tagged dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e992f2f-1ef2-4436-a775-bb4c3825c50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pprint, time\n",
    "import random\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import word_tokenize\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e5b52458-b716-4408-b680-231af10ee319",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package treebank to /Users/sarab/nltk_data...\n",
      "[nltk_data]   Package treebank is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('treebank')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2ba1e1e5-be9e-440d-b6da-59e4c1651af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the Treebank tagged sentences\n",
    "wsj = list(nltk.corpus.treebank.tagged_sents())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aa1ed279-75fb-4a0f-a2d0-c18397eb4da4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('Pierre', 'NNP'), ('Vinken', 'NNP'), (',', ','), ('61', 'CD'), ('years', 'NNS'), ('old', 'JJ'), (',', ','), ('will', 'MD'), ('join', 'VB'), ('the', 'DT'), ('board', 'NN'), ('as', 'IN'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('Nov.', 'NNP'), ('29', 'CD'), ('.', '.')], [('Mr.', 'NNP'), ('Vinken', 'NNP'), ('is', 'VBZ'), ('chairman', 'NN'), ('of', 'IN'), ('Elsevier', 'NNP'), ('N.V.', 'NNP'), (',', ','), ('the', 'DT'), ('Dutch', 'NNP'), ('publishing', 'VBG'), ('group', 'NN'), ('.', '.')], [('Rudolph', 'NNP'), ('Agnew', 'NNP'), (',', ','), ('55', 'CD'), ('years', 'NNS'), ('old', 'JJ'), ('and', 'CC'), ('former', 'JJ'), ('chairman', 'NN'), ('of', 'IN'), ('Consolidated', 'NNP'), ('Gold', 'NNP'), ('Fields', 'NNP'), ('PLC', 'NNP'), (',', ','), ('was', 'VBD'), ('named', 'VBN'), ('*-1', '-NONE-'), ('a', 'DT'), ('nonexecutive', 'JJ'), ('director', 'NN'), ('of', 'IN'), ('this', 'DT'), ('British', 'JJ'), ('industrial', 'JJ'), ('conglomerate', 'NN'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# samples: Each sentence is a list of (word, pos) tuples\n",
    "print(wsj[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "703446e0-0d94-48ac-be73-8510c574824c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100676\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Pierre', 'NNP'),\n",
       " ('Vinken', 'NNP'),\n",
       " (',', ','),\n",
       " ('61', 'CD'),\n",
       " ('years', 'NNS'),\n",
       " ('old', 'JJ'),\n",
       " (',', ','),\n",
       " ('will', 'MD'),\n",
       " ('join', 'VB'),\n",
       " ('the', 'DT')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coverting list of sents to a list of (word, pos tag) tuples to make th other data preprocessing steps easier and convenient to process\n",
    "tagged_words = [tup for sent in wsj for tup in sent]\n",
    "print(len(tagged_words))\n",
    "tagged_words[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c9f7330-945f-471a-ac6c-e51ad958afb0",
   "metadata": {},
   "source": [
    "### 2. Exploratory Analysis\n",
    "\n",
    "We can explore the data to understand the POS tags. We can try to get the tags and words details.\n",
    "\n",
    "1. How many unique tags are there in the corpus? \n",
    "2. Which is the most frequent tag in the corpus?\n",
    "3. Which tag is most commonly assigned to the following words:\n",
    "    - \"bank\"\n",
    "    - \"executive\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe8dc1bf-2cf0-4329-b563-1e477100ed70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of unique POS tags in the corpus\n",
    "tags = [pair[1] for pair in tagged_words]\n",
    "unique_tags = set(tags)\n",
    "len(unique_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5ac7c052-0435-4144-84b2-7e3a2f33e5bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'NN': 13166,\n",
       "         'IN': 9857,\n",
       "         'NNP': 9410,\n",
       "         'DT': 8165,\n",
       "         '-NONE-': 6592,\n",
       "         'NNS': 6047,\n",
       "         'JJ': 5834,\n",
       "         ',': 4886,\n",
       "         '.': 3874,\n",
       "         'CD': 3546,\n",
       "         'VBD': 3043,\n",
       "         'RB': 2822,\n",
       "         'VB': 2554,\n",
       "         'CC': 2265,\n",
       "         'TO': 2179,\n",
       "         'VBN': 2134,\n",
       "         'VBZ': 2125,\n",
       "         'PRP': 1716,\n",
       "         'VBG': 1460,\n",
       "         'VBP': 1321,\n",
       "         'MD': 927,\n",
       "         'POS': 824,\n",
       "         'PRP$': 766,\n",
       "         '$': 724,\n",
       "         '``': 712,\n",
       "         \"''\": 694,\n",
       "         ':': 563,\n",
       "         'WDT': 445,\n",
       "         'JJR': 381,\n",
       "         'NNPS': 244,\n",
       "         'WP': 241,\n",
       "         'RP': 216,\n",
       "         'JJS': 182,\n",
       "         'WRB': 178,\n",
       "         'RBR': 136,\n",
       "         '-RRB-': 126,\n",
       "         '-LRB-': 120,\n",
       "         'EX': 88,\n",
       "         'RBS': 35,\n",
       "         'PDT': 27,\n",
       "         '#': 16,\n",
       "         'WP$': 14,\n",
       "         'LS': 13,\n",
       "         'FW': 4,\n",
       "         'UH': 3,\n",
       "         'SYM': 1})"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most frequent tag in the dataset\n",
    "from collections import Counter\n",
    "result_counts = Counter(tags)\n",
    "result_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5e6e3f2f-48e5-4d53-9106-84aeae66aa63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('NN', 13166), ('IN', 9857), ('NNP', 9410), ('DT', 8165), ('-NONE-', 6592)]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most common tags\n",
    "tag_counts.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "41d526fc-6737-4a04-a4e8-81e73552b131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('bank', 'NN'), ('Bank', 'NNP'), ('bank', 'NN'), ('Bank', 'NNP'), ('bank', 'NN'), ('Bank', 'NNP'), ('bank', 'NN'), ('Bank', 'NNP'), ('bank', 'NN'), ('bank', 'NN'), ('bank', 'NN'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('bank', 'NN'), ('bank', 'NN'), ('bank', 'NN'), ('bank', 'NN'), ('bank', 'NN'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('bank', 'NN'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('bank', 'NN'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('bank', 'NN'), ('bank', 'NN'), ('Bank', 'NNP'), ('bank', 'NN'), ('bank', 'NN'), ('bank', 'NN'), ('Bank', 'NNP'), ('bank', 'NN'), ('bank', 'NN'), ('bank', 'NN'), ('bank', 'NN'), ('bank', 'NN'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('bank', 'NN'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('Bank', 'NNP'), ('bank', 'NN'), ('bank', 'NN'), ('Bank', 'NNP'), ('bank', 'NN'), ('bank', 'NN'), ('Bank', 'NNP'), ('bank', 'NN'), ('bank', 'NN'), ('bank', 'NN'), ('bank', 'NN'), ('bank', 'NN'), ('bank', 'NN'), ('bank', 'NN'), ('bank', 'NN'), ('Bank', 'NNP'), ('bank', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Most commonly tag assigned to the word bank.\n",
    "bank = [pair for pair in tagged_words if pair[0].lower() == 'bank']\n",
    "print(bank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fab937fa-f94c-45d0-8a6b-6c9215815c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('executive', 'NN'), ('executive', 'JJ'), ('executive', 'JJ'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'JJ'), ('executive', 'JJ'), ('executive', 'JJ'), ('executive', 'NN'), ('executive', 'JJ'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'JJ'), ('executive', 'JJ'), ('executive', 'JJ'), ('executive', 'JJ'), ('executive', 'JJ'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'JJ'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'JJ'), ('executive', 'JJ'), ('executive', 'JJ'), ('executive', 'JJ'), ('executive', 'JJ'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'JJ'), ('executive', 'JJ'), ('executive', 'NN'), ('executive', 'JJ'), ('executive', 'JJ'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'JJ'), ('executive', 'NN'), ('executive', 'JJ'), ('executive', 'JJ'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'JJ'), ('executive', 'NN'), ('executive', 'NN'), ('executive', 'JJ'), ('executive', 'JJ'), ('executive', 'NN'), ('executive', 'JJ')]\n"
     ]
    }
   ],
   "source": [
    "# Most commonly tag assigned to the word executive.\n",
    "executive = [pair for pair in tagged_words if pair[0].lower() == 'executive']\n",
    "print(executive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b92f2d05-58aa-44c3-92ab-6a5b73c73502",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3881038448899113\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('reported', 'VBD'),\n",
       " ('stopped', 'VBD'),\n",
       " ('studied', 'VBD'),\n",
       " ('led', 'VBD'),\n",
       " ('worked', 'VBD'),\n",
       " ('explained', 'VBD'),\n",
       " ('imposed', 'VBD'),\n",
       " ('dumped', 'VBD'),\n",
       " ('poured', 'VBD'),\n",
       " ('mixed', 'VBD'),\n",
       " ('described', 'VBD'),\n",
       " ('ventilated', 'VBD'),\n",
       " ('contracted', 'VBD'),\n",
       " ('continued', 'VBD'),\n",
       " ('eased', 'VBD'),\n",
       " ('ended', 'VBD'),\n",
       " ('lengthened', 'VBD'),\n",
       " ('reached', 'VBD'),\n",
       " ('resigned', 'VBD'),\n",
       " ('approved', 'VBD')]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words with the tag 'VBD' (verb, past tense) end with 'ed'\n",
    "past_tense_verbs = [pair for pair in tagged_words if pair[1]=='VBD']\n",
    "ed_verbs = [pair for pair in past_tense_verbs if pair[0].endswith('ed')]\n",
    "print(len(ed_verbs) / len(past_tense_verbs))\n",
    "ed_verbs[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7ef7f447-f180-4536-a795-14736def7ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9972602739726028\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('publishing', 'VBG'),\n",
       " ('causing', 'VBG'),\n",
       " ('using', 'VBG'),\n",
       " ('talking', 'VBG'),\n",
       " ('having', 'VBG'),\n",
       " ('making', 'VBG'),\n",
       " ('surviving', 'VBG'),\n",
       " ('including', 'VBG'),\n",
       " ('including', 'VBG'),\n",
       " ('according', 'VBG'),\n",
       " ('remaining', 'VBG'),\n",
       " ('according', 'VBG'),\n",
       " ('declining', 'VBG'),\n",
       " ('rising', 'VBG'),\n",
       " ('yielding', 'VBG'),\n",
       " ('waiving', 'VBG'),\n",
       " ('holding', 'VBG'),\n",
       " ('holding', 'VBG'),\n",
       " ('cutting', 'VBG'),\n",
       " ('manufacturing', 'VBG')]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Words with the tag 'VBG' end with 'ing'\n",
    "participle_verbs = [pair for pair in tagged_words if pair[1]=='VBG']\n",
    "ing_verbs = [pair for pair in participle_verbs if pair[0].endswith('ing')]\n",
    "print(len(ing_verbs) / len(participle_verbs))\n",
    "ing_verbs[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4dfe0a-18b6-45d6-b7bf-68380980bf00",
   "metadata": {},
   "source": [
    "## 3. Lexicon and Rule-Based Models for POS Tagging\n",
    "\n",
    "Let's now see lexicon and rule-based models for POS tagging. We'll first split the corpus into training and test sets and then use built-in NLTK taggers. \n",
    "\n",
    "### 3.1 Splitting into Train and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6bad6e0b-1d7c-44c4-941e-9b5eb8c6523d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2739\n",
      "1175\n",
      "[[('Sen.', 'NNP'), ('Danforth', 'NNP'), ('and', 'CC'), ('others', 'NNS'), ('also', 'RB'), ('want', 'VBP'), ('the', 'DT'), ('department', 'NN'), ('to', 'TO'), ('require', 'VB'), ('additional', 'JJ'), ('safety', 'NN'), ('equipment', 'NN'), ('*ICH*-1', '-NONE-'), ('in', 'IN'), ('light', 'JJ'), ('trucks', 'NNS'), ('and', 'CC'), ('minivans', 'NNS'), (',', ','), ('including', 'VBG'), ('air', 'NN'), ('bags', 'NNS'), ('or', 'CC'), ('automatic', 'JJ'), ('seat', 'NN'), ('belts', 'NNS'), ('in', 'IN'), ('front', 'JJ'), ('seats', 'NNS'), ('and', 'CC'), ('improved', 'VBN'), ('side-crash', 'JJ'), ('protection', 'NN'), ('.', '.')], [('The', 'DT'), ('company', 'NN'), ('said', 'VBD'), ('0', '-NONE-'), ('local', 'JJ'), ('authorities', 'NNS'), ('held', 'VBD'), ('hearings', 'NNS'), ('on', 'IN'), ('the', 'DT'), ('allegations', 'NNS'), ('last', 'JJ'), ('spring', 'NN'), ('and', 'CC'), ('had', 'VBD'), ('returned', 'VBN'), ('the', 'DT'), ('plant', 'NN'), ('to', 'TO'), ('``', '``'), ('routine', 'JJ'), ('inspection', 'NN'), (\"''\", \"''\"), ('in', 'IN'), ('August', 'NNP'), ('.', '.')]]\n"
     ]
    }
   ],
   "source": [
    "# splitting into train and test\n",
    "random.seed(1234)\n",
    "train_set, test_set = train_test_split(wsj, test_size=0.3)\n",
    "\n",
    "print(len(train_set))\n",
    "print(len(test_set))\n",
    "print(train_set[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40205ebe-4f88-401f-af70-d93c35077054",
   "metadata": {},
   "source": [
    "### 3.2 Lexicon (Unigram) Tagger\n",
    "\n",
    "In NLTK, the `UnigramTagger()`  can be used to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0bb8f99e-cc97-4551-9558-241bc2079e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vn/9wjp26gd3jq9s2fykd_nc4600000gn/T/ipykernel_2778/2670269465.py:3: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  unigram_tagger.evaluate(test_set)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.8748310086721404"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lexicon (or unigram tagger)\n",
    "unigram_tagger = nltk.UnigramTagger(train_set)\n",
    "unigram_tagger.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aef68c-80b7-4ce9-aa2e-e4bed83f4095",
   "metadata": {},
   "source": [
    "### 3.3. Rule-Based (Regular Expression) Tagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e912ed1c-608d-460f-b9c1-3ca625f5dff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify patterns for tagging\n",
    "# example from the NLTK book\n",
    "patterns = [\n",
    "    (r'.*ing$', 'VBG'),              # gerund\n",
    "    (r'.*ed$', 'VBD'),               # past tense\n",
    "    (r'.*es$', 'VBZ'),               # 3rd singular present\n",
    "    (r'.*ould$', 'MD'),              # modals\n",
    "    (r'.*\\'s$', 'NN$'),              # possessive nouns\n",
    "    (r'.*s$', 'NNS'),                # plural nouns\n",
    "    (r'^-?[0-9]+(.[0-9]+)?$', 'CD'), # cardinal numbers\n",
    "    (r'.*', 'NN')                    # nouns\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0df9f569-f5aa-4779-8dc4-415d158880d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "regexp_tagger = nltk.RegexpTagger(patterns)\n",
    "# help(regexp_tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "72afb043-250c-4735-a302-cefbfce92ad0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vn/9wjp26gd3jq9s2fykd_nc4600000gn/T/ipykernel_2778/792752471.py:1: DeprecationWarning: \n",
      "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
      "  instead.\n",
      "  regexp_tagger.evaluate(test_set)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.21871599564744287"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexp_tagger.evaluate(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "455ea22b-e1e8-4e83-a4d5-c670bf9b1351",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfddbe5-2692-4a3c-9308-de068d32ce44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
